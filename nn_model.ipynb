{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w1SLPNR7G6ZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4da10944-9dd5-4efc-84b7-7c81eb21841a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa082d90-8622-49ea-9943-2a8461fb968f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aa082d90-8622-49ea-9943-2a8461fb968f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final_x_train.csv to final_x_train.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "HRxPlTYgDh4r",
        "outputId": "8b887876-f4bc-4afe-809f-a3c1039d648e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-652a803f-5c0e-478d-a433-a236f7de55b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-652a803f-5c0e-478d-a433-a236f7de55b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final_y_train.csv to final_y_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "LmsbtVXVDpZh",
        "outputId": "e6c8e96b-eaa0-476e-e07e-187124faf0d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b15a5325-636d-4350-97a6-09e10d91d109\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b15a5325-636d-4350-97a6-09e10d91d109\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final_test.csv to final_test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "YgaBCK08Ds-o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv('final_x_train.csv')\n",
        "Y_train = pd.read_csv('final_y_train.csv')\n",
        "df_test = pd.read_csv('final_test.csv')"
      ],
      "metadata": {
        "id": "3sjA2xuxD1ki"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyNl3B6QEIiE",
        "outputId": "a3dd7624-983f-43a3-ee5a-c8ca41417385"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10762 entries, 0 to 10761\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype\n",
            "---  ------                   --------------  -----\n",
            " 0   Unnamed: 0               10762 non-null  int64\n",
            " 1   10                       10762 non-null  bool \n",
            " 2   2                        10762 non-null  bool \n",
            " 3   3                        10762 non-null  bool \n",
            " 4   4                        10762 non-null  bool \n",
            " 5   5                        10762 non-null  bool \n",
            " 6   6                        10762 non-null  bool \n",
            " 7   7                        10762 non-null  bool \n",
            " 8   8                        10762 non-null  bool \n",
            " 9   9                        10762 non-null  bool \n",
            " 10  > 10                     10762 non-null  bool \n",
            " 11  Y                        10762 non-null  bool \n",
            " 12  Builder Floor Apartment  10762 non-null  bool \n",
            " 13  Penthouse                10762 non-null  bool \n",
            " 14  Residential House        10762 non-null  bool \n",
            " 15  Villa                    10762 non-null  bool \n",
            " 16  Builder                  10762 non-null  bool \n",
            " 17  Owner                    10762 non-null  bool \n",
            " 18  Resale                   10762 non-null  bool \n",
            " 19  2.0                      10762 non-null  bool \n",
            " 20  3.0                      10762 non-null  bool \n",
            " 21  4.0                      10762 non-null  bool \n",
            " 22  5.0                      10762 non-null  bool \n",
            " 23  6.0                      10762 non-null  bool \n",
            " 24  7.0                      10762 non-null  bool \n",
            " 25  8.0                      10762 non-null  bool \n",
            " 26  9.0                      10762 non-null  bool \n",
            " 27  10.0                     10762 non-null  bool \n",
            " 28  Semi-Furnished           10762 non-null  bool \n",
            " 29  Unfurnished              10762 non-null  bool \n",
            "dtypes: bool(29), int64(1)\n",
            "memory usage: 389.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNMtcyKgELSw",
        "outputId": "23853eeb-e498-4bb0-e8f7-4359ee278ae1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10762 entries, 0 to 10761\n",
            "Data columns (total 29 columns):\n",
            " #   Column                   Non-Null Count  Dtype\n",
            "---  ------                   --------------  -----\n",
            " 0   10                       10762 non-null  bool \n",
            " 1   2                        10762 non-null  bool \n",
            " 2   3                        10762 non-null  bool \n",
            " 3   4                        10762 non-null  bool \n",
            " 4   5                        10762 non-null  bool \n",
            " 5   6                        10762 non-null  bool \n",
            " 6   7                        10762 non-null  bool \n",
            " 7   8                        10762 non-null  bool \n",
            " 8   9                        10762 non-null  bool \n",
            " 9   > 10                     10762 non-null  bool \n",
            " 10  Y                        10762 non-null  bool \n",
            " 11  Builder Floor Apartment  10762 non-null  bool \n",
            " 12  Penthouse                10762 non-null  bool \n",
            " 13  Residential House        10762 non-null  bool \n",
            " 14  Villa                    10762 non-null  bool \n",
            " 15  Builder                  10762 non-null  bool \n",
            " 16  Owner                    10762 non-null  bool \n",
            " 17  Resale                   10762 non-null  bool \n",
            " 18  2.0                      10762 non-null  bool \n",
            " 19  3.0                      10762 non-null  bool \n",
            " 20  4.0                      10762 non-null  bool \n",
            " 21  5.0                      10762 non-null  bool \n",
            " 22  6.0                      10762 non-null  bool \n",
            " 23  7.0                      10762 non-null  bool \n",
            " 24  8.0                      10762 non-null  bool \n",
            " 25  9.0                      10762 non-null  bool \n",
            " 26  10.0                     10762 non-null  bool \n",
            " 27  Semi-Furnished           10762 non-null  bool \n",
            " 28  Unfurnished              10762 non-null  bool \n",
            "dtypes: bool(29)\n",
            "memory usage: 304.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "Y_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkMV2aLjEUZc",
        "outputId": "5910e90c-2c3e-48ae-bfaf-10c1050abe60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10762 entries, 0 to 10761\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Price   10762 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 84.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "hiqWNgfWEYCY",
        "outputId": "c152b089-ee60-4161-c986-6e30ba4c4007"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c206c539-3ad0-4e60-b09a-d471b191f825\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c206c539-3ad0-4e60-b09a-d471b191f825\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "-_LTqZEsE3eZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "df_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf0t3TCpFAsQ",
        "outputId": "6ce7cc03-78da-4ba2-fb3a-997fc4316fe0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2690 entries, 0 to 2689\n",
            "Data columns (total 29 columns):\n",
            " #   Column                   Non-Null Count  Dtype\n",
            "---  ------                   --------------  -----\n",
            " 0   10                       2690 non-null   bool \n",
            " 1   2                        2690 non-null   bool \n",
            " 2   3                        2690 non-null   bool \n",
            " 3   4                        2690 non-null   bool \n",
            " 4   5                        2690 non-null   bool \n",
            " 5   6                        2690 non-null   bool \n",
            " 6   7                        2690 non-null   bool \n",
            " 7   8                        2690 non-null   bool \n",
            " 8   9                        2690 non-null   bool \n",
            " 9   > 10                     2690 non-null   bool \n",
            " 10  Y                        2690 non-null   bool \n",
            " 11  Builder Floor Apartment  2690 non-null   bool \n",
            " 12  Penthouse                2690 non-null   bool \n",
            " 13  Residential House        2690 non-null   bool \n",
            " 14  Villa                    2690 non-null   bool \n",
            " 15  Builder                  2690 non-null   bool \n",
            " 16  Owner                    2690 non-null   bool \n",
            " 17  Resale                   2690 non-null   bool \n",
            " 18  2.0                      2690 non-null   bool \n",
            " 19  3.0                      2690 non-null   bool \n",
            " 20  4.0                      2690 non-null   bool \n",
            " 21  5.0                      2690 non-null   bool \n",
            " 22  6.0                      2690 non-null   bool \n",
            " 23  7.0                      2690 non-null   bool \n",
            " 24  8.0                      2690 non-null   bool \n",
            " 25  9.0                      2690 non-null   bool \n",
            " 26  10.0                     2690 non-null   bool \n",
            " 27  Semi-Furnished           2690 non-null   bool \n",
            " 28  Unfurnished              2690 non-null   bool \n",
            "dtypes: bool(29)\n",
            "memory usage: 76.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqsdBfGkFCmW",
        "outputId": "ec14f7c2-e357-4a7a-a6d5-ce34eab52455"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU, PReLU, ELU\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "0YyIFtcAFNF3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialising the ANN\n",
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "KMJh4eVaFhzk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialize the regressor\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding input layer\n",
        "regressor.add(Dense(units=50, kernel_initializer='he_uniform', activation='relu', input_dim=29))\n",
        "\n",
        "# Adding hidden layers\n",
        "regressor.add(Dense(units=25, kernel_initializer='he_uniform', activation='relu'))\n",
        "\n",
        "# Output layer with linear activation for regression\n",
        "regressor.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "regressor.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "1ckS2_5GFofK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model = regressor.fit(X_train.values, Y_train.values, validation_split=0.2, batch_size=10, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUzQgr9IICUI",
        "outputId": "f5aaca7e-bc6c-44a1-9b3a-59be177ff182"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "861/861 [==============================] - 6s 4ms/step - loss: 67375739174912.0000 - val_loss: 65691617067008.0000\n",
            "Epoch 2/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 66597947441152.0000 - val_loss: 64256116523008.0000\n",
            "Epoch 3/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 64325586780160.0000 - val_loss: 61166906769408.0000\n",
            "Epoch 4/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 60324166238208.0000 - val_loss: 56375166107648.0000\n",
            "Epoch 5/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 54689903149056.0000 - val_loss: 50094510440448.0000\n",
            "Epoch 6/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 47730487459840.0000 - val_loss: 42733511114752.0000\n",
            "Epoch 7/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 39940205314048.0000 - val_loss: 34869090451456.0000\n",
            "Epoch 8/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 31972923539456.0000 - val_loss: 27212663226368.0000\n",
            "Epoch 9/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 24552922939392.0000 - val_loss: 20480880803840.0000\n",
            "Epoch 10/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 18389336588288.0000 - val_loss: 15332713431040.0000\n",
            "Epoch 11/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 13994597285888.0000 - val_loss: 12053610758144.0000\n",
            "Epoch 12/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 11392048431104.0000 - val_loss: 10321165025280.0000\n",
            "Epoch 13/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 10002697814016.0000 - val_loss: 9391101181952.0000\n",
            "Epoch 14/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 9178107084800.0000 - val_loss: 8771767631872.0000\n",
            "Epoch 15/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 8584265990144.0000 - val_loss: 8276157661184.0000\n",
            "Epoch 16/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 8097411629056.0000 - val_loss: 7850489806848.0000\n",
            "Epoch 17/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 7685112070144.0000 - val_loss: 7485055827968.0000\n",
            "Epoch 18/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 7333356240896.0000 - val_loss: 7169730150400.0000\n",
            "Epoch 19/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 7036893921280.0000 - val_loss: 6908247801856.0000\n",
            "Epoch 20/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 6789478219776.0000 - val_loss: 6688698531840.0000\n",
            "Epoch 21/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 6586522664960.0000 - val_loss: 6510142816256.0000\n",
            "Epoch 22/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 6422892904448.0000 - val_loss: 6364779773952.0000\n",
            "Epoch 23/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 6292196294656.0000 - val_loss: 6250596663296.0000\n",
            "Epoch 24/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 6188107300864.0000 - val_loss: 6159847653376.0000\n",
            "Epoch 25/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 6106682228736.0000 - val_loss: 6087256834048.0000\n",
            "Epoch 26/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 6044173467648.0000 - val_loss: 6029350273024.0000\n",
            "Epoch 27/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5994184179712.0000 - val_loss: 5982943969280.0000\n",
            "Epoch 28/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5954445770752.0000 - val_loss: 5947883257856.0000\n",
            "Epoch 29/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5922628829184.0000 - val_loss: 5915227455488.0000\n",
            "Epoch 30/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5895083786240.0000 - val_loss: 5889649016832.0000\n",
            "Epoch 31/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5872116826112.0000 - val_loss: 5862928678912.0000\n",
            "Epoch 32/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5851992031232.0000 - val_loss: 5842002247680.0000\n",
            "Epoch 33/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5833461596160.0000 - val_loss: 5821862248448.0000\n",
            "Epoch 34/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5816598921216.0000 - val_loss: 5805607747584.0000\n",
            "Epoch 35/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5800271544320.0000 - val_loss: 5788994633728.0000\n",
            "Epoch 36/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5785862537216.0000 - val_loss: 5771371741184.0000\n",
            "Epoch 37/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5771676352512.0000 - val_loss: 5754856669184.0000\n",
            "Epoch 38/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5758358913024.0000 - val_loss: 5740504809472.0000\n",
            "Epoch 39/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5746278793216.0000 - val_loss: 5726449696768.0000\n",
            "Epoch 40/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5733618810880.0000 - val_loss: 5714696208384.0000\n",
            "Epoch 41/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5721705938944.0000 - val_loss: 5700219043840.0000\n",
            "Epoch 42/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5709957693440.0000 - val_loss: 5685137375232.0000\n",
            "Epoch 43/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5698849603584.0000 - val_loss: 5673706323968.0000\n",
            "Epoch 44/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5687784505344.0000 - val_loss: 5661027467264.0000\n",
            "Epoch 45/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5677169770496.0000 - val_loss: 5649612668928.0000\n",
            "Epoch 46/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5666704457728.0000 - val_loss: 5637810946048.0000\n",
            "Epoch 47/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5656692129792.0000 - val_loss: 5625778012160.0000\n",
            "Epoch 48/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5646689763328.0000 - val_loss: 5614254686208.0000\n",
            "Epoch 49/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5636853596160.0000 - val_loss: 5602888646656.0000\n",
            "Epoch 50/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5627571601408.0000 - val_loss: 5592003379200.0000\n",
            "Epoch 51/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5618306908160.0000 - val_loss: 5582768046080.0000\n",
            "Epoch 52/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5609136062464.0000 - val_loss: 5573155225600.0000\n",
            "Epoch 53/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5600425541632.0000 - val_loss: 5564512337920.0000\n",
            "Epoch 54/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5591318134784.0000 - val_loss: 5556842004480.0000\n",
            "Epoch 55/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5583750037504.0000 - val_loss: 5543115620352.0000\n",
            "Epoch 56/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5574690340864.0000 - val_loss: 5531544584192.0000\n",
            "Epoch 57/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5566739513344.0000 - val_loss: 5524008468480.0000\n",
            "Epoch 58/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5557990195200.0000 - val_loss: 5519355936768.0000\n",
            "Epoch 59/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5551289794560.0000 - val_loss: 5505712914432.0000\n",
            "Epoch 60/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5543111426048.0000 - val_loss: 5497152864256.0000\n",
            "Epoch 61/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5535838502912.0000 - val_loss: 5488702390272.0000\n",
            "Epoch 62/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5527635492864.0000 - val_loss: 5483254513664.0000\n",
            "Epoch 63/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5520995385344.0000 - val_loss: 5472953827328.0000\n",
            "Epoch 64/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5513095938048.0000 - val_loss: 5462832971776.0000\n",
            "Epoch 65/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5506377711616.0000 - val_loss: 5454810841088.0000\n",
            "Epoch 66/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5499724496896.0000 - val_loss: 5447912783872.0000\n",
            "Epoch 67/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5492713717760.0000 - val_loss: 5441365475328.0000\n",
            "Epoch 68/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5486165884928.0000 - val_loss: 5433187106816.0000\n",
            "Epoch 69/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5479570341888.0000 - val_loss: 5425638932480.0000\n",
            "Epoch 70/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5472941768704.0000 - val_loss: 5419167121408.0000\n",
            "Epoch 71/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5466526056448.0000 - val_loss: 5410579808256.0000\n",
            "Epoch 72/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5460429635584.0000 - val_loss: 5403872067584.0000\n",
            "Epoch 73/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5453739196416.0000 - val_loss: 5397914058752.0000\n",
            "Epoch 74/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5447964164096.0000 - val_loss: 5389033144320.0000\n",
            "Epoch 75/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5441891860480.0000 - val_loss: 5383862616064.0000\n",
            "Epoch 76/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5436179742720.0000 - val_loss: 5378054029312.0000\n",
            "Epoch 77/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5430212820992.0000 - val_loss: 5371881586688.0000\n",
            "Epoch 78/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5424462430208.0000 - val_loss: 5362643107840.0000\n",
            "Epoch 79/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5419172364288.0000 - val_loss: 5358540554240.0000\n",
            "Epoch 80/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5413070176256.0000 - val_loss: 5351241416704.0000\n",
            "Epoch 81/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5407881822208.0000 - val_loss: 5345901543424.0000\n",
            "Epoch 82/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5402469597184.0000 - val_loss: 5338510131200.0000\n",
            "Epoch 83/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5397724790784.0000 - val_loss: 5334026420224.0000\n",
            "Epoch 84/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5392271671296.0000 - val_loss: 5328226222080.0000\n",
            "Epoch 85/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5386762977280.0000 - val_loss: 5324435619840.0000\n",
            "Epoch 86/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5381980946432.0000 - val_loss: 5316918902784.0000\n",
            "Epoch 87/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5377363017728.0000 - val_loss: 5310032904192.0000\n",
            "Epoch 88/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5372314124288.0000 - val_loss: 5306649673728.0000\n",
            "Epoch 89/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5367188160512.0000 - val_loss: 5299444383744.0000\n",
            "Epoch 90/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5362727518208.0000 - val_loss: 5293811433472.0000\n",
            "Epoch 91/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5358180368384.0000 - val_loss: 5289505456128.0000\n",
            "Epoch 92/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5353519448064.0000 - val_loss: 5285006540800.0000\n",
            "Epoch 93/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5349132730368.0000 - val_loss: 5279972851712.0000\n",
            "Epoch 94/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5344852443136.0000 - val_loss: 5275153596416.0000\n",
            "Epoch 95/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5340349857792.0000 - val_loss: 5270276669440.0000\n",
            "Epoch 96/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5336277712896.0000 - val_loss: 5267807272960.0000\n",
            "Epoch 97/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5331676037120.0000 - val_loss: 5260504989696.0000\n",
            "Epoch 98/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5327432974336.0000 - val_loss: 5254617235456.0000\n",
            "Epoch 99/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5323753521152.0000 - val_loss: 5251531800576.0000\n",
            "Epoch 100/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5319535624192.0000 - val_loss: 5249360723968.0000\n",
            "Epoch 101/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5315474489344.0000 - val_loss: 5243516485632.0000\n",
            "Epoch 102/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5311385042944.0000 - val_loss: 5237769240576.0000\n",
            "Epoch 103/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5307565080576.0000 - val_loss: 5233901568000.0000\n",
            "Epoch 104/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5303778672640.0000 - val_loss: 5229281017856.0000\n",
            "Epoch 105/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5300254408704.0000 - val_loss: 5227074289664.0000\n",
            "Epoch 106/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5296312811520.0000 - val_loss: 5223486586880.0000\n",
            "Epoch 107/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5292677398528.0000 - val_loss: 5217928609792.0000\n",
            "Epoch 108/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5289248555008.0000 - val_loss: 5214098161664.0000\n",
            "Epoch 109/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5285628346368.0000 - val_loss: 5211589967872.0000\n",
            "Epoch 110/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5281988739072.0000 - val_loss: 5208022188032.0000\n",
            "Epoch 111/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5278577197056.0000 - val_loss: 5202624643072.0000\n",
            "Epoch 112/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5275327660032.0000 - val_loss: 5199752593408.0000\n",
            "Epoch 113/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5272283643904.0000 - val_loss: 5197166804992.0000\n",
            "Epoch 114/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5268832780288.0000 - val_loss: 5192980889600.0000\n",
            "Epoch 115/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5265679712256.0000 - val_loss: 5190210551808.0000\n",
            "Epoch 116/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5262053212160.0000 - val_loss: 5185121812480.0000\n",
            "Epoch 117/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5259727470592.0000 - val_loss: 5181690871808.0000\n",
            "Epoch 118/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5256472166400.0000 - val_loss: 5180119056384.0000\n",
            "Epoch 119/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5253276106752.0000 - val_loss: 5177393283072.0000\n",
            "Epoch 120/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5250214264832.0000 - val_loss: 5172491714560.0000\n",
            "Epoch 121/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5247641583616.0000 - val_loss: 5169638014976.0000\n",
            "Epoch 122/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5244496379904.0000 - val_loss: 5165294813184.0000\n",
            "Epoch 123/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5242041663488.0000 - val_loss: 5165704282112.0000\n",
            "Epoch 124/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5239360454656.0000 - val_loss: 5163233312768.0000\n",
            "Epoch 125/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5236445413376.0000 - val_loss: 5157900255232.0000\n",
            "Epoch 126/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5232472883200.0000 - val_loss: 5159725826048.0000\n",
            "Epoch 127/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5231522349056.0000 - val_loss: 5153288093696.0000\n",
            "Epoch 128/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5228331532288.0000 - val_loss: 5150170152960.0000\n",
            "Epoch 129/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5225949691904.0000 - val_loss: 5147084193792.0000\n",
            "Epoch 130/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5222873169920.0000 - val_loss: 5146688880640.0000\n",
            "Epoch 131/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5221112086528.0000 - val_loss: 5143382196224.0000\n",
            "Epoch 132/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5218119974912.0000 - val_loss: 5143312990208.0000\n",
            "Epoch 133/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5216326909952.0000 - val_loss: 5138813550592.0000\n",
            "Epoch 134/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5213837066240.0000 - val_loss: 5135287713792.0000\n",
            "Epoch 135/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5211170537472.0000 - val_loss: 5134376501248.0000\n",
            "Epoch 136/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5209093308416.0000 - val_loss: 5129489088512.0000\n",
            "Epoch 137/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5207339040768.0000 - val_loss: 5127761035264.0000\n",
            "Epoch 138/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5204876984320.0000 - val_loss: 5126981419008.0000\n",
            "Epoch 139/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5202315837440.0000 - val_loss: 5122706898944.0000\n",
            "Epoch 140/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5200607182848.0000 - val_loss: 5120154140672.0000\n",
            "Epoch 141/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5198485913600.0000 - val_loss: 5119548063744.0000\n",
            "Epoch 142/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5196066324480.0000 - val_loss: 5117517496320.0000\n",
            "Epoch 143/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5194267492352.0000 - val_loss: 5116275458048.0000\n",
            "Epoch 144/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5192377958400.0000 - val_loss: 5112862343168.0000\n",
            "Epoch 145/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5190482132992.0000 - val_loss: 5111085531136.0000\n",
            "Epoch 146/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5188953833472.0000 - val_loss: 5110205251584.0000\n",
            "Epoch 147/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5186467659776.0000 - val_loss: 5107889995776.0000\n",
            "Epoch 148/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5184611155968.0000 - val_loss: 5103857172480.0000\n",
            "Epoch 149/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5183013650432.0000 - val_loss: 5104204251136.0000\n",
            "Epoch 150/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5180903391232.0000 - val_loss: 5100602916864.0000\n",
            "Epoch 151/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5179544961024.0000 - val_loss: 5098937778176.0000\n",
            "Epoch 152/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5177601425408.0000 - val_loss: 5096394981376.0000\n",
            "Epoch 153/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5175936811008.0000 - val_loss: 5094764969984.0000\n",
            "Epoch 154/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5174023684096.0000 - val_loss: 5095615889408.0000\n",
            "Epoch 155/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5172143063040.0000 - val_loss: 5094996180992.0000\n",
            "Epoch 156/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5170635735040.0000 - val_loss: 5090265006080.0000\n",
            "Epoch 157/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5168999956480.0000 - val_loss: 5091380690944.0000\n",
            "Epoch 158/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5167880077312.0000 - val_loss: 5089255227392.0000\n",
            "Epoch 159/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5165919240192.0000 - val_loss: 5086460248064.0000\n",
            "Epoch 160/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5164347424768.0000 - val_loss: 5084070019072.0000\n",
            "Epoch 161/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5162984800256.0000 - val_loss: 5083679424512.0000\n",
            "Epoch 162/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5161291874304.0000 - val_loss: 5081530892288.0000\n",
            "Epoch 163/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5160261648384.0000 - val_loss: 5082703724544.0000\n",
            "Epoch 164/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5158524157952.0000 - val_loss: 5078040182784.0000\n",
            "Epoch 165/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5157132697600.0000 - val_loss: 5079086137344.0000\n",
            "Epoch 166/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5155846619136.0000 - val_loss: 5077436727296.0000\n",
            "Epoch 167/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5154281095168.0000 - val_loss: 5074792218624.0000\n",
            "Epoch 168/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5153387184128.0000 - val_loss: 5073808654336.0000\n",
            "Epoch 169/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5151702646784.0000 - val_loss: 5071883993088.0000\n",
            "Epoch 170/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5150003429376.0000 - val_loss: 5073625153536.0000\n",
            "Epoch 171/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5149091168256.0000 - val_loss: 5069534134272.0000\n",
            "Epoch 172/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5147701280768.0000 - val_loss: 5067326881792.0000\n",
            "Epoch 173/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5146549944320.0000 - val_loss: 5066256809984.0000\n",
            "Epoch 174/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5145201999872.0000 - val_loss: 5064788803584.0000\n",
            "Epoch 175/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5144478482432.0000 - val_loss: 5065131687936.0000\n",
            "Epoch 176/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5143017291776.0000 - val_loss: 5063697760256.0000\n",
            "Epoch 177/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5141868052480.0000 - val_loss: 5063922155520.0000\n",
            "Epoch 178/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5140692074496.0000 - val_loss: 5061397708800.0000\n",
            "Epoch 179/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5139699073024.0000 - val_loss: 5062510772224.0000\n",
            "Epoch 180/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5138379964416.0000 - val_loss: 5058893185024.0000\n",
            "Epoch 181/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5137684234240.0000 - val_loss: 5058630516736.0000\n",
            "Epoch 182/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5136283336704.0000 - val_loss: 5056955940864.0000\n",
            "Epoch 183/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5135161360384.0000 - val_loss: 5057494384640.0000\n",
            "Epoch 184/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5134062452736.0000 - val_loss: 5057022525440.0000\n",
            "Epoch 185/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5132936282112.0000 - val_loss: 5054256381952.0000\n",
            "Epoch 186/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5131970543616.0000 - val_loss: 5052390440960.0000\n",
            "Epoch 187/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5130801905664.0000 - val_loss: 5054904926208.0000\n",
            "Epoch 188/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5130197401600.0000 - val_loss: 5051839938560.0000\n",
            "Epoch 189/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5129035579392.0000 - val_loss: 5051851472896.0000\n",
            "Epoch 190/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5128080850944.0000 - val_loss: 5049689833472.0000\n",
            "Epoch 191/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5127399276544.0000 - val_loss: 5051314601984.0000\n",
            "Epoch 192/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5126365904896.0000 - val_loss: 5047717462016.0000\n",
            "Epoch 193/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5125322047488.0000 - val_loss: 5047048470528.0000\n",
            "Epoch 194/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5124740087808.0000 - val_loss: 5046256271360.0000\n",
            "Epoch 195/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5123706191872.0000 - val_loss: 5046154559488.0000\n",
            "Epoch 196/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5122801795072.0000 - val_loss: 5044356251648.0000\n",
            "Epoch 197/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5122080899072.0000 - val_loss: 5046791569408.0000\n",
            "Epoch 198/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5120969408512.0000 - val_loss: 5045620834304.0000\n",
            "Epoch 199/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5120212860928.0000 - val_loss: 5045110702080.0000\n",
            "Epoch 200/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5119455264768.0000 - val_loss: 5042239700992.0000\n",
            "Epoch 201/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5118309695488.0000 - val_loss: 5045355020288.0000\n",
            "Epoch 202/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5117077618688.0000 - val_loss: 5039345106944.0000\n",
            "Epoch 203/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5117074472960.0000 - val_loss: 5038487371776.0000\n",
            "Epoch 204/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5116137570304.0000 - val_loss: 5040619651072.0000\n",
            "Epoch 205/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5115523104768.0000 - val_loss: 5038581743616.0000\n",
            "Epoch 206/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5114475577344.0000 - val_loss: 5041611079680.0000\n",
            "Epoch 207/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5113996378112.0000 - val_loss: 5036681723904.0000\n",
            "Epoch 208/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5112842420224.0000 - val_loss: 5040284106752.0000\n",
            "Epoch 209/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5112397824000.0000 - val_loss: 5039618260992.0000\n",
            "Epoch 210/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5112022433792.0000 - val_loss: 5036047859712.0000\n",
            "Epoch 211/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5110914088960.0000 - val_loss: 5034224386048.0000\n",
            "Epoch 212/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5110377742336.0000 - val_loss: 5033171091456.0000\n",
            "Epoch 213/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5109882290176.0000 - val_loss: 5033883074560.0000\n",
            "Epoch 214/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5109079605248.0000 - val_loss: 5034005757952.0000\n",
            "Epoch 215/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5108911308800.0000 - val_loss: 5033694330880.0000\n",
            "Epoch 216/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5107790381056.0000 - val_loss: 5033686466560.0000\n",
            "Epoch 217/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5106956763136.0000 - val_loss: 5030315294720.0000\n",
            "Epoch 218/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5106618073088.0000 - val_loss: 5032346386432.0000\n",
            "Epoch 219/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5105844748288.0000 - val_loss: 5030247137280.0000\n",
            "Epoch 220/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5105285857280.0000 - val_loss: 5029769510912.0000\n",
            "Epoch 221/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5104038051840.0000 - val_loss: 5032762671104.0000\n",
            "Epoch 222/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5104255631360.0000 - val_loss: 5028378050560.0000\n",
            "Epoch 223/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5103582969856.0000 - val_loss: 5027896754176.0000\n",
            "Epoch 224/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5102893531136.0000 - val_loss: 5027391864832.0000\n",
            "Epoch 225/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5102493499392.0000 - val_loss: 5026468069376.0000\n",
            "Epoch 226/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5102028455936.0000 - val_loss: 5026438709248.0000\n",
            "Epoch 227/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5101380960256.0000 - val_loss: 5026081669120.0000\n",
            "Epoch 228/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5100281004032.0000 - val_loss: 5027875782656.0000\n",
            "Epoch 229/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5100391104512.0000 - val_loss: 5026693513216.0000\n",
            "Epoch 230/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5099331518464.0000 - val_loss: 5027073622016.0000\n",
            "Epoch 231/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5099047354368.0000 - val_loss: 5025547419648.0000\n",
            "Epoch 232/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5098740645888.0000 - val_loss: 5027033251840.0000\n",
            "Epoch 233/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5098020274176.0000 - val_loss: 5027271802880.0000\n",
            "Epoch 234/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5097625485312.0000 - val_loss: 5023638487040.0000\n",
            "Epoch 235/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5096963833856.0000 - val_loss: 5021450633216.0000\n",
            "Epoch 236/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5096603123712.0000 - val_loss: 5023279349760.0000\n",
            "Epoch 237/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5095327531008.0000 - val_loss: 5020922675200.0000\n",
            "Epoch 238/1000\n",
            "861/861 [==============================] - 9s 11ms/step - loss: 5095660453888.0000 - val_loss: 5020638511104.0000\n",
            "Epoch 239/1000\n",
            "861/861 [==============================] - 6s 7ms/step - loss: 5095422951424.0000 - val_loss: 5021332144128.0000\n",
            "Epoch 240/1000\n",
            "861/861 [==============================] - 9s 10ms/step - loss: 5094286295040.0000 - val_loss: 5025388036096.0000\n",
            "Epoch 241/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5094148931584.0000 - val_loss: 5022469324800.0000\n",
            "Epoch 242/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5093032722432.0000 - val_loss: 5018777812992.0000\n",
            "Epoch 243/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5093236670464.0000 - val_loss: 5018369392640.0000\n",
            "Epoch 244/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5093333663744.0000 - val_loss: 5019508146176.0000\n",
            "Epoch 245/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5092457054208.0000 - val_loss: 5020696182784.0000\n",
            "Epoch 246/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5092048633856.0000 - val_loss: 5019715239936.0000\n",
            "Epoch 247/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5091914416128.0000 - val_loss: 5019393851392.0000\n",
            "Epoch 248/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5091019456512.0000 - val_loss: 5021747380224.0000\n",
            "Epoch 249/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5090716418048.0000 - val_loss: 5020296151040.0000\n",
            "Epoch 250/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5089790001152.0000 - val_loss: 5016064622592.0000\n",
            "Epoch 251/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5089794719744.0000 - val_loss: 5019225554944.0000\n",
            "Epoch 252/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5089482244096.0000 - val_loss: 5017214386176.0000\n",
            "Epoch 253/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5088906575872.0000 - val_loss: 5018768375808.0000\n",
            "Epoch 254/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5088554778624.0000 - val_loss: 5016690098176.0000\n",
            "Epoch 255/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5088135872512.0000 - val_loss: 5015573364736.0000\n",
            "Epoch 256/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5087630458880.0000 - val_loss: 5016205131776.0000\n",
            "Epoch 257/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5087441715200.0000 - val_loss: 5015485808640.0000\n",
            "Epoch 258/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5087055839232.0000 - val_loss: 5016382341120.0000\n",
            "Epoch 259/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5086705090560.0000 - val_loss: 5014762291200.0000\n",
            "Epoch 260/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5086430887936.0000 - val_loss: 5015238344704.0000\n",
            "Epoch 261/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5086084333568.0000 - val_loss: 5015441768448.0000\n",
            "Epoch 262/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5085646553088.0000 - val_loss: 5013050490880.0000\n",
            "Epoch 263/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5085552181248.0000 - val_loss: 5013145387008.0000\n",
            "Epoch 264/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5084568092672.0000 - val_loss: 5017052381184.0000\n",
            "Epoch 265/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5084524576768.0000 - val_loss: 5012270874624.0000\n",
            "Epoch 266/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5084378824704.0000 - val_loss: 5014641704960.0000\n",
            "Epoch 267/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5083977220096.0000 - val_loss: 5012847067136.0000\n",
            "Epoch 268/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5083617034240.0000 - val_loss: 5012652556288.0000\n",
            "Epoch 269/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5083324481536.0000 - val_loss: 5011504365568.0000\n",
            "Epoch 270/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5083043987456.0000 - val_loss: 5012401946624.0000\n",
            "Epoch 271/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5082953285632.0000 - val_loss: 5012897398784.0000\n",
            "Epoch 272/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5081696567296.0000 - val_loss: 5010261803008.0000\n",
            "Epoch 273/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5082399637504.0000 - val_loss: 5011689963520.0000\n",
            "Epoch 274/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5081768394752.0000 - val_loss: 5010644533248.0000\n",
            "Epoch 275/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5081674547200.0000 - val_loss: 5010123915264.0000\n",
            "Epoch 276/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5080969904128.0000 - val_loss: 5013425881088.0000\n",
            "Epoch 277/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5080989302784.0000 - val_loss: 5011372769280.0000\n",
            "Epoch 278/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5080704090112.0000 - val_loss: 5011574095872.0000\n",
            "Epoch 279/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5080381128704.0000 - val_loss: 5009807769600.0000\n",
            "Epoch 280/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5079740448768.0000 - val_loss: 5011744489472.0000\n",
            "Epoch 281/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5079209345024.0000 - val_loss: 5007855845376.0000\n",
            "Epoch 282/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5079139614720.0000 - val_loss: 5010383437824.0000\n",
            "Epoch 283/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5078874849280.0000 - val_loss: 5008329801728.0000\n",
            "Epoch 284/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5078992814080.0000 - val_loss: 5008093347840.0000\n",
            "Epoch 285/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5078832906240.0000 - val_loss: 5009785225216.0000\n",
            "Epoch 286/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5077707259904.0000 - val_loss: 5012876427264.0000\n",
            "Epoch 287/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5078237315072.0000 - val_loss: 5010336251904.0000\n",
            "Epoch 288/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5077820506112.0000 - val_loss: 5009616404480.0000\n",
            "Epoch 289/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5077640675328.0000 - val_loss: 5008537944064.0000\n",
            "Epoch 290/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5077188214784.0000 - val_loss: 5007967518720.0000\n",
            "Epoch 291/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5077100658688.0000 - val_loss: 5008745037824.0000\n",
            "Epoch 292/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5076448444416.0000 - val_loss: 5006178123776.0000\n",
            "Epoch 293/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5076517126144.0000 - val_loss: 5007527641088.0000\n",
            "Epoch 294/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5077049278464.0000 - val_loss: 5007867904000.0000\n",
            "Epoch 295/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5076130725888.0000 - val_loss: 5007471017984.0000\n",
            "Epoch 296/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5075626885120.0000 - val_loss: 5008271081472.0000\n",
            "Epoch 297/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5075571834880.0000 - val_loss: 5006299234304.0000\n",
            "Epoch 298/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5075322273792.0000 - val_loss: 5005563133952.0000\n",
            "Epoch 299/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5074285756416.0000 - val_loss: 5009018716160.0000\n",
            "Epoch 300/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5075010846720.0000 - val_loss: 5006351138816.0000\n",
            "Epoch 301/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5074660098048.0000 - val_loss: 5007531311104.0000\n",
            "Epoch 302/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5074713575424.0000 - val_loss: 5006646837248.0000\n",
            "Epoch 303/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5073943396352.0000 - val_loss: 5005985710080.0000\n",
            "Epoch 304/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5074227560448.0000 - val_loss: 5006751694848.0000\n",
            "Epoch 305/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5073646649344.0000 - val_loss: 5004525568000.0000\n",
            "Epoch 306/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5073735254016.0000 - val_loss: 5004536578048.0000\n",
            "Epoch 307/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5073385029632.0000 - val_loss: 5006193328128.0000\n",
            "Epoch 308/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5073122361344.0000 - val_loss: 5008524836864.0000\n",
            "Epoch 309/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5072925229056.0000 - val_loss: 5007460532224.0000\n",
            "Epoch 310/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5072701882368.0000 - val_loss: 5004772507648.0000\n",
            "Epoch 311/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5072672522240.0000 - val_loss: 5005196656640.0000\n",
            "Epoch 312/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5072224780288.0000 - val_loss: 5005223395328.0000\n",
            "Epoch 313/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5071986753536.0000 - val_loss: 5006293467136.0000\n",
            "Epoch 314/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5071787524096.0000 - val_loss: 5006436597760.0000\n",
            "Epoch 315/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5071575711744.0000 - val_loss: 5002729881600.0000\n",
            "Epoch 316/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5071548973056.0000 - val_loss: 5002634985472.0000\n",
            "Epoch 317/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5070958100480.0000 - val_loss: 5006600699904.0000\n",
            "Epoch 318/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5071344500736.0000 - val_loss: 5004576948224.0000\n",
            "Epoch 319/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5071114338304.0000 - val_loss: 5003971919872.0000\n",
            "Epoch 320/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5070724792320.0000 - val_loss: 5005194559488.0000\n",
            "Epoch 321/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5070532902912.0000 - val_loss: 5003796807680.0000\n",
            "Epoch 322/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5070497251328.0000 - val_loss: 5004101419008.0000\n",
            "Epoch 323/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5070284390400.0000 - val_loss: 5003703484416.0000\n",
            "Epoch 324/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5069730742272.0000 - val_loss: 5002175184896.0000\n",
            "Epoch 325/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5069817774080.0000 - val_loss: 5003344871424.0000\n",
            "Epoch 326/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5069858668544.0000 - val_loss: 5004046893056.0000\n",
            "Epoch 327/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5069588135936.0000 - val_loss: 5005685293056.0000\n",
            "Epoch 328/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5069421936640.0000 - val_loss: 5005106479104.0000\n",
            "Epoch 329/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5069697187840.0000 - val_loss: 5004088836096.0000\n",
            "Epoch 330/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5068930678784.0000 - val_loss: 5002608771072.0000\n",
            "Epoch 331/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5068942737408.0000 - val_loss: 5003268325376.0000\n",
            "Epoch 332/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5068842074112.0000 - val_loss: 5002595139584.0000\n",
            "Epoch 333/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5068780208128.0000 - val_loss: 5000850833408.0000\n",
            "Epoch 334/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5068371263488.0000 - val_loss: 5002738270208.0000\n",
            "Epoch 335/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5067818139648.0000 - val_loss: 5000522629120.0000\n",
            "Epoch 336/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5068313067520.0000 - val_loss: 5002856235008.0000\n",
            "Epoch 337/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5068094963712.0000 - val_loss: 5000769568768.0000\n",
            "Epoch 338/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5068033622016.0000 - val_loss: 5001310633984.0000\n",
            "Epoch 339/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5067490983936.0000 - val_loss: 5001778823168.0000\n",
            "Epoch 340/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5067224645632.0000 - val_loss: 5003572936704.0000\n",
            "Epoch 341/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5067495702528.0000 - val_loss: 5000879144960.0000\n",
            "Epoch 342/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5067743690752.0000 - val_loss: 5001118744576.0000\n",
            "Epoch 343/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5067202101248.0000 - val_loss: 5002701045760.0000\n",
            "Epoch 344/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5066749116416.0000 - val_loss: 5000696168448.0000\n",
            "Epoch 345/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5066600742912.0000 - val_loss: 5000201240576.0000\n",
            "Epoch 346/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5066648453120.0000 - val_loss: 4999972651008.0000\n",
            "Epoch 347/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5066933665792.0000 - val_loss: 5001840164864.0000\n",
            "Epoch 348/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5066467573760.0000 - val_loss: 4999858880512.0000\n",
            "Epoch 349/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5066614374400.0000 - val_loss: 5002094444544.0000\n",
            "Epoch 350/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5066068066304.0000 - val_loss: 5000970895360.0000\n",
            "Epoch 351/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5066046046208.0000 - val_loss: 5001708044288.0000\n",
            "Epoch 352/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5066040279040.0000 - val_loss: 5002162077696.0000\n",
            "Epoch 353/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5065735143424.0000 - val_loss: 5001044819968.0000\n",
            "Epoch 354/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5066056007680.0000 - val_loss: 5002469834752.0000\n",
            "Epoch 355/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5065778135040.0000 - val_loss: 5000264155136.0000\n",
            "Epoch 356/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5065244934144.0000 - val_loss: 5002759241728.0000\n",
            "Epoch 357/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5065228156928.0000 - val_loss: 5003835080704.0000\n",
            "Epoch 358/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5065474572288.0000 - val_loss: 5002047258624.0000\n",
            "Epoch 359/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5065208233984.0000 - val_loss: 4999456751616.0000\n",
            "Epoch 360/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5065212952576.0000 - val_loss: 4999498170368.0000\n",
            "Epoch 361/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5064732180480.0000 - val_loss: 5000288272384.0000\n",
            "Epoch 362/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5064770977792.0000 - val_loss: 5001871097856.0000\n",
            "Epoch 363/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5064293875712.0000 - val_loss: 4998455361536.0000\n",
            "Epoch 364/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5064229912576.0000 - val_loss: 5000138326016.0000\n",
            "Epoch 365/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5064287059968.0000 - val_loss: 5000366391296.0000\n",
            "Epoch 366/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5064032780288.0000 - val_loss: 5001764667392.0000\n",
            "Epoch 367/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5064224669696.0000 - val_loss: 4999628718080.0000\n",
            "Epoch 368/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063932116992.0000 - val_loss: 5002129047552.0000\n",
            "Epoch 369/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063978254336.0000 - val_loss: 4998744768512.0000\n",
            "Epoch 370/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063781646336.0000 - val_loss: 4998734807040.0000\n",
            "Epoch 371/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5063612301312.0000 - val_loss: 5000362721280.0000\n",
            "Epoch 372/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063826735104.0000 - val_loss: 4999954300928.0000\n",
            "Epoch 373/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063730266112.0000 - val_loss: 4999795965952.0000\n",
            "Epoch 374/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063367983104.0000 - val_loss: 4999251230720.0000\n",
            "Epoch 375/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5062619824128.0000 - val_loss: 5001877913600.0000\n",
            "Epoch 376/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063504822272.0000 - val_loss: 4999821131776.0000\n",
            "Epoch 377/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063135199232.0000 - val_loss: 5000450801664.0000\n",
            "Epoch 378/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5063080673280.0000 - val_loss: 4997572460544.0000\n",
            "Epoch 379/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5062560579584.0000 - val_loss: 4997297733632.0000\n",
            "Epoch 380/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5062828490752.0000 - val_loss: 4999394361344.0000\n",
            "Epoch 381/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5062624542720.0000 - val_loss: 5001357819904.0000\n",
            "Epoch 382/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5062621396992.0000 - val_loss: 4998513033216.0000\n",
            "Epoch 383/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5062527025152.0000 - val_loss: 4998962348032.0000\n",
            "Epoch 384/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5062204588032.0000 - val_loss: 4997438767104.0000\n",
            "Epoch 385/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5062495043584.0000 - val_loss: 4999034699776.0000\n",
            "Epoch 386/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5062438944768.0000 - val_loss: 4997759107072.0000\n",
            "Epoch 387/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5062132236288.0000 - val_loss: 4999312572416.0000\n",
            "Epoch 388/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5062039437312.0000 - val_loss: 4999249657856.0000\n",
            "Epoch 389/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5062001688576.0000 - val_loss: 5000199143424.0000\n",
            "Epoch 390/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5061984387072.0000 - val_loss: 4998024921088.0000\n",
            "Epoch 391/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5061682921472.0000 - val_loss: 4996743561216.0000\n",
            "Epoch 392/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5061349998592.0000 - val_loss: 4995998547968.0000\n",
            "Epoch 393/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5062006931456.0000 - val_loss: 4997734465536.0000\n",
            "Epoch 394/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5061646221312.0000 - val_loss: 4999579959296.0000\n",
            "Epoch 395/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5061119836160.0000 - val_loss: 4997385289728.0000\n",
            "Epoch 396/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5061440700416.0000 - val_loss: 4999094468608.0000\n",
            "Epoch 397/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5061154439168.0000 - val_loss: 4996163174400.0000\n",
            "Epoch 398/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5061100961792.0000 - val_loss: 4996576837632.0000\n",
            "Epoch 399/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5061189566464.0000 - val_loss: 4997791612928.0000\n",
            "Epoch 400/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5061221548032.0000 - val_loss: 4997901713408.0000\n",
            "Epoch 401/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5060982996992.0000 - val_loss: 4998303842304.0000\n",
            "Epoch 402/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5060846157824.0000 - val_loss: 4996496621568.0000\n",
            "Epoch 403/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5060115824640.0000 - val_loss: 4994985099264.0000\n",
            "Epoch 404/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5061251956736.0000 - val_loss: 4997391581184.0000\n",
            "Epoch 405/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5060533157888.0000 - val_loss: 4995424452608.0000\n",
            "Epoch 406/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5060196564992.0000 - val_loss: 5000833007616.0000\n",
            "Epoch 407/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5060507992064.0000 - val_loss: 4999130644480.0000\n",
            "Epoch 408/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5060708270080.0000 - val_loss: 4997782700032.0000\n",
            "Epoch 409/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059824844800.0000 - val_loss: 4999769227264.0000\n",
            "Epoch 410/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5060784816128.0000 - val_loss: 4998108282880.0000\n",
            "Epoch 411/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5059997335552.0000 - val_loss: 5000374779904.0000\n",
            "Epoch 412/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5060532109312.0000 - val_loss: 4998574374912.0000\n",
            "Epoch 413/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5060092231680.0000 - val_loss: 4996538564608.0000\n",
            "Epoch 414/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5060087513088.0000 - val_loss: 4997494865920.0000\n",
            "Epoch 415/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5059856302080.0000 - val_loss: 4996906090496.0000\n",
            "Epoch 416/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059850534912.0000 - val_loss: 4996131192832.0000\n",
            "Epoch 417/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059757735936.0000 - val_loss: 4998485770240.0000\n",
            "Epoch 418/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5059376054272.0000 - val_loss: 4998625755136.0000\n",
            "Epoch 419/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059631382528.0000 - val_loss: 4997544148992.0000\n",
            "Epoch 420/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059036839936.0000 - val_loss: 4994961506304.0000\n",
            "Epoch 421/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059147464704.0000 - val_loss: 4999659126784.0000\n",
            "Epoch 422/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5059680665600.0000 - val_loss: 4997301927936.0000\n",
            "Epoch 423/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059653926912.0000 - val_loss: 4997660540928.0000\n",
            "Epoch 424/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058347401216.0000 - val_loss: 4994098528256.0000\n",
            "Epoch 425/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059467280384.0000 - val_loss: 4999139557376.0000\n",
            "Epoch 426/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5059379200000.0000 - val_loss: 4995489988608.0000\n",
            "Epoch 427/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059436347392.0000 - val_loss: 4995400859648.0000\n",
            "Epoch 428/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059388637184.0000 - val_loss: 4996933877760.0000\n",
            "Epoch 429/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058805628928.0000 - val_loss: 4997529993216.0000\n",
            "Epoch 430/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5058397208576.0000 - val_loss: 5000737587200.0000\n",
            "Epoch 431/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5058863300608.0000 - val_loss: 4996582604800.0000\n",
            "Epoch 432/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058893185024.0000 - val_loss: 4998730612736.0000\n",
            "Epoch 433/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5059143794688.0000 - val_loss: 4996322033664.0000\n",
            "Epoch 434/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5058014478336.0000 - val_loss: 4999020019712.0000\n",
            "Epoch 435/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058726461440.0000 - val_loss: 4996908711936.0000\n",
            "Epoch 436/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058423947264.0000 - val_loss: 4995844407296.0000\n",
            "Epoch 437/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058657255424.0000 - val_loss: 4997728174080.0000\n",
            "Epoch 438/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5058418704384.0000 - val_loss: 4997355405312.0000\n",
            "Epoch 439/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058329575424.0000 - val_loss: 4997820973056.0000\n",
            "Epoch 440/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058233106432.0000 - val_loss: 4998845956096.0000\n",
            "Epoch 441/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058591719424.0000 - val_loss: 4997557256192.0000\n",
            "Epoch 442/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5058743238656.0000 - val_loss: 4996946460672.0000\n",
            "Epoch 443/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058159181824.0000 - val_loss: 4997261557760.0000\n",
            "Epoch 444/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058275573760.0000 - val_loss: 4997764349952.0000\n",
            "Epoch 445/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058188017664.0000 - val_loss: 4998693388288.0000\n",
            "Epoch 446/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5058044887040.0000 - val_loss: 4998323240960.0000\n",
            "Epoch 447/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5058406645760.0000 - val_loss: 4996497670144.0000\n",
            "Epoch 448/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057762820096.0000 - val_loss: 4996886167552.0000\n",
            "Epoch 449/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057338146816.0000 - val_loss: 4993673330688.0000\n",
            "Epoch 450/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5057380089856.0000 - val_loss: 4998904676352.0000\n",
            "Epoch 451/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057794801664.0000 - val_loss: 4998958153728.0000\n",
            "Epoch 452/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057522171904.0000 - val_loss: 4994993487872.0000\n",
            "Epoch 453/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5057879212032.0000 - val_loss: 4995790405632.0000\n",
            "Epoch 454/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5057832550400.0000 - val_loss: 4996015325184.0000\n",
            "Epoch 455/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057548910592.0000 - val_loss: 4994602369024.0000\n",
            "Epoch 456/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057397915648.0000 - val_loss: 4994463956992.0000\n",
            "Epoch 457/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5057573027840.0000 - val_loss: 4998374096896.0000\n",
            "Epoch 458/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5057581940736.0000 - val_loss: 4997432475648.0000\n",
            "Epoch 459/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057390575616.0000 - val_loss: 4995372023808.0000\n",
            "Epoch 460/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057623359488.0000 - val_loss: 4995659333632.0000\n",
            "Epoch 461/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5057141014528.0000 - val_loss: 4994517434368.0000\n",
            "Epoch 462/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5057539997696.0000 - val_loss: 4996460445696.0000\n",
            "Epoch 463/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057398439936.0000 - val_loss: 4995417636864.0000\n",
            "Epoch 464/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056676495360.0000 - val_loss: 4998032261120.0000\n",
            "Epoch 465/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5056840073216.0000 - val_loss: 5000960409600.0000\n",
            "Epoch 466/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5057364361216.0000 - val_loss: 4997121572864.0000\n",
            "Epoch 467/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5057099071488.0000 - val_loss: 4995566534656.0000\n",
            "Epoch 468/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056829063168.0000 - val_loss: 4995588554752.0000\n",
            "Epoch 469/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5057109032960.0000 - val_loss: 4995516727296.0000\n",
            "Epoch 470/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056912424960.0000 - val_loss: 4994546270208.0000\n",
            "Epoch 471/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056922386432.0000 - val_loss: 4994506424320.0000\n",
            "Epoch 472/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056631406592.0000 - val_loss: 4994495938560.0000\n",
            "Epoch 473/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5056885686272.0000 - val_loss: 4995943497728.0000\n",
            "Epoch 474/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056865239040.0000 - val_loss: 4996596236288.0000\n",
            "Epoch 475/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056714244096.0000 - val_loss: 4998601637888.0000\n",
            "Epoch 476/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056832733184.0000 - val_loss: 4998324289536.0000\n",
            "Epoch 477/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5056521306112.0000 - val_loss: 4995467444224.0000\n",
            "Epoch 478/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056778207232.0000 - val_loss: 4995827105792.0000\n",
            "Epoch 479/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056367689728.0000 - val_loss: 4996778688512.0000\n",
            "Epoch 480/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056732069888.0000 - val_loss: 4996586799104.0000\n",
            "Epoch 481/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5056497188864.0000 - val_loss: 4997632229376.0000\n",
            "Epoch 482/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056699039744.0000 - val_loss: 4995615293440.0000\n",
            "Epoch 483/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056372932608.0000 - val_loss: 4995636789248.0000\n",
            "Epoch 484/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056332562432.0000 - val_loss: 4994968846336.0000\n",
            "Epoch 485/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5056403341312.0000 - val_loss: 4994346516480.0000\n",
            "Epoch 486/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5055851790336.0000 - val_loss: 4996415881216.0000\n",
            "Epoch 487/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056261783552.0000 - val_loss: 4994851405824.0000\n",
            "Epoch 488/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056364019712.0000 - val_loss: 4994182938624.0000\n",
            "Epoch 489/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5055927287808.0000 - val_loss: 4996905566208.0000\n",
            "Epoch 490/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5055807225856.0000 - val_loss: 4997813108736.0000\n",
            "Epoch 491/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055974473728.0000 - val_loss: 4998477905920.0000\n",
            "Epoch 492/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055950880768.0000 - val_loss: 4995625779200.0000\n",
            "Epoch 493/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5055990726656.0000 - val_loss: 4995128229888.0000\n",
            "Epoch 494/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055795691520.0000 - val_loss: 4996908711936.0000\n",
            "Epoch 495/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055537741824.0000 - val_loss: 4997850857472.0000\n",
            "Epoch 496/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5056155877376.0000 - val_loss: 4996668588032.0000\n",
            "Epoch 497/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5055725436928.0000 - val_loss: 4996642373632.0000\n",
            "Epoch 498/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055973949440.0000 - val_loss: 4995622633472.0000\n",
            "Epoch 499/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055520964608.0000 - val_loss: 4994312437760.0000\n",
            "Epoch 500/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055943540736.0000 - val_loss: 4996358209536.0000\n",
            "Epoch 501/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5055468535808.0000 - val_loss: 4997934219264.0000\n",
            "Epoch 502/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054972035072.0000 - val_loss: 4993589444608.0000\n",
            "Epoch 503/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055501041664.0000 - val_loss: 4994656370688.0000\n",
            "Epoch 504/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055346900992.0000 - val_loss: 4994617049088.0000\n",
            "Epoch 505/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5054966792192.0000 - val_loss: 4997138350080.0000\n",
            "Epoch 506/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055465914368.0000 - val_loss: 4995340566528.0000\n",
            "Epoch 507/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055654133760.0000 - val_loss: 4996662820864.0000\n",
            "Epoch 508/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055639977984.0000 - val_loss: 4993575288832.0000\n",
            "Epoch 509/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5055545081856.0000 - val_loss: 4995458531328.0000\n",
            "Epoch 510/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055502614528.0000 - val_loss: 4995680305152.0000\n",
            "Epoch 511/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055425019904.0000 - val_loss: 4995952410624.0000\n",
            "Epoch 512/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054818942976.0000 - val_loss: 4992602734592.0000\n",
            "Epoch 513/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5055418204160.0000 - val_loss: 4994325020672.0000\n",
            "Epoch 514/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054289936384.0000 - val_loss: 4997637472256.0000\n",
            "Epoch 515/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055321210880.0000 - val_loss: 4996446814208.0000\n",
            "Epoch 516/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055262490624.0000 - val_loss: 4995506765824.0000\n",
            "Epoch 517/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5055048581120.0000 - val_loss: 4994012020736.0000\n",
            "Epoch 518/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054953160704.0000 - val_loss: 4996387569664.0000\n",
            "Epoch 519/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055229460480.0000 - val_loss: 4995852271616.0000\n",
            "Epoch 520/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5055003492352.0000 - val_loss: 4993796538368.0000\n",
            "Epoch 521/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5055019220992.0000 - val_loss: 4993810169856.0000\n",
            "Epoch 522/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054796922880.0000 - val_loss: 4995164930048.0000\n",
            "Epoch 523/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055089999872.0000 - val_loss: 4994265776128.0000\n",
            "Epoch 524/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5055260393472.0000 - val_loss: 4994444558336.0000\n",
            "Epoch 525/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5055015026688.0000 - val_loss: 4995411345408.0000\n",
            "Epoch 526/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055099961344.0000 - val_loss: 4995876388864.0000\n",
            "Epoch 527/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055235227648.0000 - val_loss: 4995571253248.0000\n",
            "Epoch 528/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5055086329856.0000 - val_loss: 4996745658368.0000\n",
            "Epoch 529/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5054677385216.0000 - val_loss: 4995474259968.0000\n",
            "Epoch 530/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5055045435392.0000 - val_loss: 4994843541504.0000\n",
            "Epoch 531/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054676336640.0000 - val_loss: 4993696399360.0000\n",
            "Epoch 532/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5054844633088.0000 - val_loss: 4993769275392.0000\n",
            "Epoch 533/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5054529011712.0000 - val_loss: 4993987903488.0000\n",
            "Epoch 534/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054546837504.0000 - val_loss: 4994124218368.0000\n",
            "Epoch 535/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054044045312.0000 - val_loss: 4992206372864.0000\n",
            "Epoch 536/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5054596644864.0000 - val_loss: 4994821521408.0000\n",
            "Epoch 537/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5054407901184.0000 - val_loss: 4993250230272.0000\n",
            "Epoch 538/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054353899520.0000 - val_loss: 4992531431424.0000\n",
            "Epoch 539/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053950197760.0000 - val_loss: 4991420465152.0000\n",
            "Epoch 540/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5054446174208.0000 - val_loss: 4994233794560.0000\n",
            "Epoch 541/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5054209196032.0000 - val_loss: 4993949106176.0000\n",
            "Epoch 542/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054722998272.0000 - val_loss: 4994226978816.0000\n",
            "Epoch 543/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054017830912.0000 - val_loss: 4996147445760.0000\n",
            "Epoch 544/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5054473437184.0000 - val_loss: 4996924964864.0000\n",
            "Epoch 545/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054376443904.0000 - val_loss: 4994027225088.0000\n",
            "Epoch 546/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054340792320.0000 - val_loss: 4994116354048.0000\n",
            "Epoch 547/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054192943104.0000 - val_loss: 4995836542976.0000\n",
            "Epoch 548/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5054340268032.0000 - val_loss: 4993798635520.0000\n",
            "Epoch 549/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5054212341760.0000 - val_loss: 4993248657408.0000\n",
            "Epoch 550/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054001053696.0000 - val_loss: 4992618463232.0000\n",
            "Epoch 551/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054166204416.0000 - val_loss: 4993949630464.0000\n",
            "Epoch 552/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053933420544.0000 - val_loss: 4994740256768.0000\n",
            "Epoch 553/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5053982703616.0000 - val_loss: 4994037186560.0000\n",
            "Epoch 554/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054167777280.0000 - val_loss: 4993670184960.0000\n",
            "Epoch 555/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054055579648.0000 - val_loss: 4993502937088.0000\n",
            "Epoch 556/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053991616512.0000 - val_loss: 4994368012288.0000\n",
            "Epoch 557/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053855301632.0000 - val_loss: 4992397737984.0000\n",
            "Epoch 558/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5054199758848.0000 - val_loss: 4993108672512.0000\n",
            "Epoch 559/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053832232960.0000 - val_loss: 4995706519552.0000\n",
            "Epoch 560/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053902487552.0000 - val_loss: 4993560608768.0000\n",
            "Epoch 561/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053976412160.0000 - val_loss: 4993094516736.0000\n",
            "Epoch 562/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053939712000.0000 - val_loss: 4992416088064.0000\n",
            "Epoch 563/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053967499264.0000 - val_loss: 4994385838080.0000\n",
            "Epoch 564/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5053955964928.0000 - val_loss: 4994766471168.0000\n",
            "Epoch 565/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053296934912.0000 - val_loss: 4999270105088.0000\n",
            "Epoch 566/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053756735488.0000 - val_loss: 4992702873600.0000\n",
            "Epoch 567/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5053570088960.0000 - val_loss: 4994064449536.0000\n",
            "Epoch 568/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053951246336.0000 - val_loss: 4994965700608.0000\n",
            "Epoch 569/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053610983424.0000 - val_loss: 4993225588736.0000\n",
            "Epoch 570/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053674946560.0000 - val_loss: 4993745158144.0000\n",
            "Epoch 571/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053457891328.0000 - val_loss: 4994511667200.0000\n",
            "Epoch 572/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053352509440.0000 - val_loss: 4992564461568.0000\n",
            "Epoch 573/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053606264832.0000 - val_loss: 4995579117568.0000\n",
            "Epoch 574/1000\n",
            "861/861 [==============================] - 3s 3ms/step - loss: 5053579001856.0000 - val_loss: 4993728905216.0000\n",
            "Epoch 575/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053580050432.0000 - val_loss: 4993142226944.0000\n",
            "Epoch 576/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5053671276544.0000 - val_loss: 4993808072704.0000\n",
            "Epoch 577/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053868933120.0000 - val_loss: 4992957677568.0000\n",
            "Epoch 578/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053778231296.0000 - val_loss: 4994882338816.0000\n",
            "Epoch 579/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053669703680.0000 - val_loss: 4993334116352.0000\n",
            "Epoch 580/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053759356928.0000 - val_loss: 4993252851712.0000\n",
            "Epoch 581/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053542825984.0000 - val_loss: 4994650079232.0000\n",
            "Epoch 582/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052483239936.0000 - val_loss: 4991260557312.0000\n",
            "Epoch 583/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053724229632.0000 - val_loss: 4995109879808.0000\n",
            "Epoch 584/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053239787520.0000 - val_loss: 4996212457472.0000\n",
            "Epoch 585/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053428531200.0000 - val_loss: 4993504509952.0000\n",
            "Epoch 586/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053304799232.0000 - val_loss: 4994461335552.0000\n",
            "Epoch 587/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052947759104.0000 - val_loss: 4991621267456.0000\n",
            "Epoch 588/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053348315136.0000 - val_loss: 4993811742720.0000\n",
            "Epoch 589/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053430628352.0000 - val_loss: 4992222101504.0000\n",
            "Epoch 590/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052884844544.0000 - val_loss: 4992354746368.0000\n",
            "Epoch 591/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053351985152.0000 - val_loss: 4993389690880.0000\n",
            "Epoch 592/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052777889792.0000 - val_loss: 4992087359488.0000\n",
            "Epoch 593/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053172678656.0000 - val_loss: 4994899116032.0000\n",
            "Epoch 594/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052829794304.0000 - val_loss: 4996610916352.0000\n",
            "Epoch 595/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053057859584.0000 - val_loss: 4993185218560.0000\n",
            "Epoch 596/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053021159424.0000 - val_loss: 4992096272384.0000\n",
            "Epoch 597/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053553311744.0000 - val_loss: 4992395116544.0000\n",
            "Epoch 598/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053195747328.0000 - val_loss: 4993794441216.0000\n",
            "Epoch 599/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053062578176.0000 - val_loss: 4993956446208.0000\n",
            "Epoch 600/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053029023744.0000 - val_loss: 4993851064320.0000\n",
            "Epoch 601/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052353216512.0000 - val_loss: 4991284674560.0000\n",
            "Epoch 602/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5053386588160.0000 - val_loss: 4992871694336.0000\n",
            "Epoch 603/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052578136064.0000 - val_loss: 4995672440832.0000\n",
            "Epoch 604/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052863873024.0000 - val_loss: 4993995767808.0000\n",
            "Epoch 605/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052905291776.0000 - val_loss: 4991453495296.0000\n",
            "Epoch 606/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053758308352.0000 - val_loss: 4994580873216.0000\n",
            "Epoch 607/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052099461120.0000 - val_loss: 4991503826944.0000\n",
            "Epoch 608/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052905291776.0000 - val_loss: 4994832531456.0000\n",
            "Epoch 609/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052915777536.0000 - val_loss: 4993204092928.0000\n",
            "Epoch 610/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052710780928.0000 - val_loss: 4993914503168.0000\n",
            "Epoch 611/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052579184640.0000 - val_loss: 4992179634176.0000\n",
            "Epoch 612/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5053386588160.0000 - val_loss: 4992663552000.0000\n",
            "Epoch 613/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052374712320.0000 - val_loss: 4992029687808.0000\n",
            "Epoch 614/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5053275439104.0000 - val_loss: 4992570753024.0000\n",
            "Epoch 615/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052548775936.0000 - val_loss: 4993711079424.0000\n",
            "Epoch 616/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052734373888.0000 - val_loss: 4994324496384.0000\n",
            "Epoch 617/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052509978624.0000 - val_loss: 4993503461376.0000\n",
            "Epoch 618/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052661497856.0000 - val_loss: 4993672806400.0000\n",
            "Epoch 619/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052775792640.0000 - val_loss: 4995256680448.0000\n",
            "Epoch 620/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052917874688.0000 - val_loss: 4993719468032.0000\n",
            "Epoch 621/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052983410688.0000 - val_loss: 4994042953728.0000\n",
            "Epoch 622/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052675653632.0000 - val_loss: 4992929890304.0000\n",
            "Epoch 623/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052550873088.0000 - val_loss: 4992900530176.0000\n",
            "Epoch 624/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052632137728.0000 - val_loss: 4994339176448.0000\n",
            "Epoch 625/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052619030528.0000 - val_loss: 4994317156352.0000\n",
            "Epoch 626/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052483764224.0000 - val_loss: 4991948423168.0000\n",
            "Epoch 627/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052415082496.0000 - val_loss: 4993750925312.0000\n",
            "Epoch 628/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052242591744.0000 - val_loss: 4991716163584.0000\n",
            "Epoch 629/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052709732352.0000 - val_loss: 4994026700800.0000\n",
            "Epoch 630/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052239446016.0000 - val_loss: 4991706202112.0000\n",
            "Epoch 631/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052978167808.0000 - val_loss: 4993261764608.0000\n",
            "Epoch 632/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052395683840.0000 - val_loss: 4992569180160.0000\n",
            "Epoch 633/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052165521408.0000 - val_loss: 4991372754944.0000\n",
            "Epoch 634/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052800434176.0000 - val_loss: 4992996474880.0000\n",
            "Epoch 635/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052490579968.0000 - val_loss: 4992811401216.0000\n",
            "Epoch 636/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052498968576.0000 - val_loss: 4991732416512.0000\n",
            "Epoch 637/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052308127744.0000 - val_loss: 4993269104640.0000\n",
            "Epoch 638/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052411412480.0000 - val_loss: 4993931280384.0000\n",
            "Epoch 639/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052250456064.0000 - val_loss: 4992735379456.0000\n",
            "Epoch 640/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052356362240.0000 - val_loss: 4994063400960.0000\n",
            "Epoch 641/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052318089216.0000 - val_loss: 4994466054144.0000\n",
            "Epoch 642/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052034449408.0000 - val_loss: 4991543672832.0000\n",
            "Epoch 643/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052389392384.0000 - val_loss: 4991660064768.0000\n",
            "Epoch 644/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052164997120.0000 - val_loss: 4992189071360.0000\n",
            "Epoch 645/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052174434304.0000 - val_loss: 4992229441536.0000\n",
            "Epoch 646/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052004564992.0000 - val_loss: 4993843200000.0000\n",
            "Epoch 647/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052088975360.0000 - val_loss: 4994041380864.0000\n",
            "Epoch 648/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051613446144.0000 - val_loss: 4991448776704.0000\n",
            "Epoch 649/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052507881472.0000 - val_loss: 4994118975488.0000\n",
            "Epoch 650/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052165521408.0000 - val_loss: 4993418526720.0000\n",
            "Epoch 651/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052140355584.0000 - val_loss: 4992065863680.0000\n",
            "Epoch 652/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052091596800.0000 - val_loss: 4991573557248.0000\n",
            "Epoch 653/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052403548160.0000 - val_loss: 4992396689408.0000\n",
            "Epoch 654/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5052099461120.0000 - val_loss: 4992496828416.0000\n",
            "Epoch 655/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052009807872.0000 - val_loss: 4993246560256.0000\n",
            "Epoch 656/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052090023936.0000 - val_loss: 4993099235328.0000\n",
            "Epoch 657/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052140355584.0000 - val_loss: 4993141702656.0000\n",
            "Epoch 658/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052103131136.0000 - val_loss: 4993593638912.0000\n",
            "Epoch 659/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052431859712.0000 - val_loss: 4992643629056.0000\n",
            "Epoch 660/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052247310336.0000 - val_loss: 4991867158528.0000\n",
            "Epoch 661/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5052207464448.0000 - val_loss: 4994310340608.0000\n",
            "Epoch 662/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5052161851392.0000 - val_loss: 4994096431104.0000\n",
            "Epoch 663/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051762868224.0000 - val_loss: 4991567790080.0000\n",
            "Epoch 664/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051940601856.0000 - val_loss: 4993349844992.0000\n",
            "Epoch 665/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051990933504.0000 - val_loss: 4991313510400.0000\n",
            "Epoch 666/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051996700672.0000 - val_loss: 4993456799744.0000\n",
            "Epoch 667/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051834171392.0000 - val_loss: 4995763666944.0000\n",
            "Epoch 668/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052025536512.0000 - val_loss: 4992679280640.0000\n",
            "Epoch 669/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051595096064.0000 - val_loss: 4994071789568.0000\n",
            "Epoch 670/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052166045696.0000 - val_loss: 4993146421248.0000\n",
            "Epoch 671/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052068003840.0000 - val_loss: 4994002059264.0000\n",
            "Epoch 672/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051717255168.0000 - val_loss: 4995207397376.0000\n",
            "Epoch 673/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051859337216.0000 - val_loss: 4992751108096.0000\n",
            "Epoch 674/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051463499776.0000 - val_loss: 4990504534016.0000\n",
            "Epoch 675/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051090206720.0000 - val_loss: 4996166844416.0000\n",
            "Epoch 676/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051798519808.0000 - val_loss: 4993108148224.0000\n",
            "Epoch 677/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051803762688.0000 - val_loss: 4993643970560.0000\n",
            "Epoch 678/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051688943616.0000 - val_loss: 4992248840192.0000\n",
            "Epoch 679/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051672690688.0000 - val_loss: 4995382509568.0000\n",
            "Epoch 680/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051826831360.0000 - val_loss: 4994441412608.0000\n",
            "Epoch 681/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051739275264.0000 - val_loss: 4992265093120.0000\n",
            "Epoch 682/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051712012288.0000 - val_loss: 4991519031296.0000\n",
            "Epoch 683/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051457208320.0000 - val_loss: 4994591883264.0000\n",
            "Epoch 684/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051525365760.0000 - val_loss: 4993116536832.0000\n",
            "Epoch 685/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051403730944.0000 - val_loss: 4991838322688.0000\n",
            "Epoch 686/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051712012288.0000 - val_loss: 4993367670784.0000\n",
            "Epoch 687/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051628126208.0000 - val_loss: 4991829934080.0000\n",
            "Epoch 688/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051666399232.0000 - val_loss: 4994618097664.0000\n",
            "Epoch 689/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051482898432.0000 - val_loss: 4995284467712.0000\n",
            "Epoch 690/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051662729216.0000 - val_loss: 4994235891712.0000\n",
            "Epoch 691/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052059090944.0000 - val_loss: 4994196045824.0000\n",
            "Epoch 692/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051683176448.0000 - val_loss: 4995047489536.0000\n",
            "Epoch 693/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051664302080.0000 - val_loss: 4992607453184.0000\n",
            "Epoch 694/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051223375872.0000 - val_loss: 4995856990208.0000\n",
            "Epoch 695/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051994079232.0000 - val_loss: 4996485611520.0000\n",
            "Epoch 696/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051864580096.0000 - val_loss: 4994970419200.0000\n",
            "Epoch 697/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051455635456.0000 - val_loss: 4993852112896.0000\n",
            "Epoch 698/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050846937088.0000 - val_loss: 4996606197760.0000\n",
            "Epoch 699/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5052211134464.0000 - val_loss: 4993639776256.0000\n",
            "Epoch 700/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051724595200.0000 - val_loss: 4992996999168.0000\n",
            "Epoch 701/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051464024064.0000 - val_loss: 4993300561920.0000\n",
            "Epoch 702/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051634417664.0000 - val_loss: 4992107282432.0000\n",
            "Epoch 703/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051413692416.0000 - val_loss: 4993876230144.0000\n",
            "Epoch 704/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051925921792.0000 - val_loss: 4993204617216.0000\n",
            "Epoch 705/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051635990528.0000 - val_loss: 4993672282112.0000\n",
            "Epoch 706/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051401633792.0000 - val_loss: 4994568814592.0000\n",
            "Epoch 707/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051220230144.0000 - val_loss: 4991469223936.0000\n",
            "Epoch 708/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051371749376.0000 - val_loss: 4993644494848.0000\n",
            "Epoch 709/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5051795898368.0000 - val_loss: 4993285357568.0000\n",
            "Epoch 710/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051597193216.0000 - val_loss: 4994434072576.0000\n",
            "Epoch 711/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051620261888.0000 - val_loss: 4992086835200.0000\n",
            "Epoch 712/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051486044160.0000 - val_loss: 4991352832000.0000\n",
            "Epoch 713/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051535327232.0000 - val_loss: 4992349503488.0000\n",
            "Epoch 714/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050882064384.0000 - val_loss: 4996042588160.0000\n",
            "Epoch 715/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051581464576.0000 - val_loss: 4994110062592.0000\n",
            "Epoch 716/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050608386048.0000 - val_loss: 4990265982976.0000\n",
            "Epoch 717/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051401633792.0000 - val_loss: 4993651310592.0000\n",
            "Epoch 718/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051033583616.0000 - val_loss: 4990418026496.0000\n",
            "Epoch 719/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051531132928.0000 - val_loss: 4991364366336.0000\n",
            "Epoch 720/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051434663936.0000 - val_loss: 4992898433024.0000\n",
            "Epoch 721/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051219705856.0000 - val_loss: 4991789039616.0000\n",
            "Epoch 722/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050897268736.0000 - val_loss: 4994631204864.0000\n",
            "Epoch 723/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051713585152.0000 - val_loss: 4992930414592.0000\n",
            "Epoch 724/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051553153024.0000 - val_loss: 4993151664128.0000\n",
            "Epoch 725/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050840121344.0000 - val_loss: 4991627558912.0000\n",
            "Epoch 726/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050764623872.0000 - val_loss: 4996417454080.0000\n",
            "Epoch 727/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051502297088.0000 - val_loss: 4993876230144.0000\n",
            "Epoch 728/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051352875008.0000 - val_loss: 4991626510336.0000\n",
            "Epoch 729/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051458781184.0000 - val_loss: 4991880265728.0000\n",
            "Epoch 730/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051163082752.0000 - val_loss: 4991064997888.0000\n",
            "Epoch 731/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051427323904.0000 - val_loss: 4993739915264.0000\n",
            "Epoch 732/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051331379200.0000 - val_loss: 4992593297408.0000\n",
            "Epoch 733/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051038302208.0000 - val_loss: 4993488257024.0000\n",
            "Epoch 734/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051410022400.0000 - val_loss: 4992821886976.0000\n",
            "Epoch 735/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051052457984.0000 - val_loss: 4991076007936.0000\n",
            "Epoch 736/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5051431518208.0000 - val_loss: 4992320143360.0000\n",
            "Epoch 737/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051046166528.0000 - val_loss: 4991205507072.0000\n",
            "Epoch 738/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051374370816.0000 - val_loss: 4991824691200.0000\n",
            "Epoch 739/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051076575232.0000 - val_loss: 4992635764736.0000\n",
            "Epoch 740/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5051315126272.0000 - val_loss: 4992069009408.0000\n",
            "Epoch 741/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051220754432.0000 - val_loss: 4993022164992.0000\n",
            "Epoch 742/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050942357504.0000 - val_loss: 4993845297152.0000\n",
            "Epoch 743/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051300446208.0000 - val_loss: 4995307536384.0000\n",
            "Epoch 744/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051453538304.0000 - val_loss: 4991407882240.0000\n",
            "Epoch 745/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051111178240.0000 - val_loss: 4992257228800.0000\n",
            "Epoch 746/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050741555200.0000 - val_loss: 4994025652224.0000\n",
            "Epoch 747/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051177762816.0000 - val_loss: 4993027407872.0000\n",
            "Epoch 748/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051094401024.0000 - val_loss: 4992373096448.0000\n",
            "Epoch 749/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050752565248.0000 - val_loss: 4991205507072.0000\n",
            "Epoch 750/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051029389312.0000 - val_loss: 4991135252480.0000\n",
            "Epoch 751/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050619920384.0000 - val_loss: 4990377656320.0000\n",
            "Epoch 752/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051307261952.0000 - val_loss: 4991967297536.0000\n",
            "Epoch 753/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051302543360.0000 - val_loss: 4991846187008.0000\n",
            "Epoch 754/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050958610432.0000 - val_loss: 4992607977472.0000\n",
            "Epoch 755/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051087585280.0000 - val_loss: 4991639093248.0000\n",
            "Epoch 756/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050979057664.0000 - val_loss: 4993348796416.0000\n",
            "Epoch 757/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050503004160.0000 - val_loss: 4990711103488.0000\n",
            "Epoch 758/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050937638912.0000 - val_loss: 4991427805184.0000\n",
            "Epoch 759/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051413692416.0000 - val_loss: 4992053280768.0000\n",
            "Epoch 760/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050984824832.0000 - val_loss: 4992041746432.0000\n",
            "Epoch 761/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050543374336.0000 - val_loss: 4990286954496.0000\n",
            "Epoch 762/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051259551744.0000 - val_loss: 4991994560512.0000\n",
            "Epoch 763/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050763051008.0000 - val_loss: 4991814205440.0000\n",
            "Epoch 764/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050966474752.0000 - val_loss: 4992969736192.0000\n",
            "Epoch 765/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050687029248.0000 - val_loss: 4990435328000.0000\n",
            "Epoch 766/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051201355776.0000 - val_loss: 4992751108096.0000\n",
            "Epoch 767/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050822295552.0000 - val_loss: 4994057633792.0000\n",
            "Epoch 768/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050867908608.0000 - val_loss: 4994579824640.0000\n",
            "Epoch 769/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050932920320.0000 - val_loss: 4993694302208.0000\n",
            "Epoch 770/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051411070976.0000 - val_loss: 4991484952576.0000\n",
            "Epoch 771/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050948124672.0000 - val_loss: 4991429378048.0000\n",
            "Epoch 772/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051133198336.0000 - val_loss: 4991779602432.0000\n",
            "Epoch 773/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051182481408.0000 - val_loss: 4991117950976.0000\n",
            "Epoch 774/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051110129664.0000 - val_loss: 4992569704448.0000\n",
            "Epoch 775/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050960707584.0000 - val_loss: 4993045757952.0000\n",
            "Epoch 776/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051131101184.0000 - val_loss: 4993848442880.0000\n",
            "Epoch 777/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050943406080.0000 - val_loss: 4993618804736.0000\n",
            "Epoch 778/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050944978944.0000 - val_loss: 4992312279040.0000\n",
            "Epoch 779/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5050753613824.0000 - val_loss: 4994160918528.0000\n",
            "Epoch 780/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050784022528.0000 - val_loss: 4991298306048.0000\n",
            "Epoch 781/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050705903616.0000 - val_loss: 4992715980800.0000\n",
            "Epoch 782/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5051022573568.0000 - val_loss: 4991657967616.0000\n",
            "Epoch 783/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050821246976.0000 - val_loss: 4990958567424.0000\n",
            "Epoch 784/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051036205056.0000 - val_loss: 4992620560384.0000\n",
            "Epoch 785/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050650329088.0000 - val_loss: 4994711420928.0000\n",
            "Epoch 786/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050121322496.0000 - val_loss: 4990626168832.0000\n",
            "Epoch 787/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051365982208.0000 - val_loss: 4992394067968.0000\n",
            "Epoch 788/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5051099119616.0000 - val_loss: 4992670892032.0000\n",
            "Epoch 789/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050956513280.0000 - val_loss: 4992231538688.0000\n",
            "Epoch 790/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5050849558528.0000 - val_loss: 4991833079808.0000\n",
            "Epoch 791/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050861617152.0000 - val_loss: 4991492816896.0000\n",
            "Epoch 792/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050726350848.0000 - val_loss: 4990400200704.0000\n",
            "Epoch 793/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051144208384.0000 - val_loss: 4993495597056.0000\n",
            "Epoch 794/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050593705984.0000 - val_loss: 4991292014592.0000\n",
            "Epoch 795/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050696990720.0000 - val_loss: 4991464505344.0000\n",
            "Epoch 796/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050565918720.0000 - val_loss: 4990162698240.0000\n",
            "Epoch 797/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050537607168.0000 - val_loss: 4993415905280.0000\n",
            "Epoch 798/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5050962280448.0000 - val_loss: 4991704629248.0000\n",
            "Epoch 799/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050597900288.0000 - val_loss: 4991917490176.0000\n",
            "Epoch 800/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050799226880.0000 - val_loss: 4991472893952.0000\n",
            "Epoch 801/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050317406208.0000 - val_loss: 4995004497920.0000\n",
            "Epoch 802/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050692796416.0000 - val_loss: 4992059047936.0000\n",
            "Epoch 803/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050895171584.0000 - val_loss: 4991876595712.0000\n",
            "Epoch 804/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050752565248.0000 - val_loss: 4991906480128.0000\n",
            "Epoch 805/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050681786368.0000 - val_loss: 4993282736128.0000\n",
            "Epoch 806/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050765672448.0000 - val_loss: 4992386203648.0000\n",
            "Epoch 807/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050507722752.0000 - val_loss: 4991705153536.0000\n",
            "Epoch 808/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050463158272.0000 - val_loss: 4993560608768.0000\n",
            "Epoch 809/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050990067712.0000 - val_loss: 4992658309120.0000\n",
            "Epoch 810/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050850082816.0000 - val_loss: 4992225771520.0000\n",
            "Epoch 811/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050863714304.0000 - val_loss: 4991596101632.0000\n",
            "Epoch 812/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050634076160.0000 - val_loss: 4990549098496.0000\n",
            "Epoch 813/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050726875136.0000 - val_loss: 4990389714944.0000\n",
            "Epoch 814/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5050685456384.0000 - val_loss: 4993397555200.0000\n",
            "Epoch 815/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050651377664.0000 - val_loss: 4993827471360.0000\n",
            "Epoch 816/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050722156544.0000 - val_loss: 4992816644096.0000\n",
            "Epoch 817/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5050091438080.0000 - val_loss: 4991370657792.0000\n",
            "Epoch 818/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050298531840.0000 - val_loss: 4990372937728.0000\n",
            "Epoch 819/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050564870144.0000 - val_loss: 4993231880192.0000\n",
            "Epoch 820/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050857422848.0000 - val_loss: 4992143982592.0000\n",
            "Epoch 821/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050237714432.0000 - val_loss: 4994096955392.0000\n",
            "Epoch 822/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050474692608.0000 - val_loss: 4993843200000.0000\n",
            "Epoch 823/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050289618944.0000 - val_loss: 4990623547392.0000\n",
            "Epoch 824/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049545129984.0000 - val_loss: 4996164222976.0000\n",
            "Epoch 825/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5050777731072.0000 - val_loss: 4991558352896.0000\n",
            "Epoch 826/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050146488320.0000 - val_loss: 4990021664768.0000\n",
            "Epoch 827/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050386087936.0000 - val_loss: 4989790453760.0000\n",
            "Epoch 828/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050778779648.0000 - val_loss: 4990851612672.0000\n",
            "Epoch 829/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050699612160.0000 - val_loss: 4990482513920.0000\n",
            "Epoch 830/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5051017854976.0000 - val_loss: 4991552585728.0000\n",
            "Epoch 831/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050464206848.0000 - val_loss: 4991499632640.0000\n",
            "Epoch 832/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049903742976.0000 - val_loss: 4994561474560.0000\n",
            "Epoch 833/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050506674176.0000 - val_loss: 4992714407936.0000\n",
            "Epoch 834/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050688077824.0000 - val_loss: 4991663210496.0000\n",
            "Epoch 835/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050882588672.0000 - val_loss: 4991268421632.0000\n",
            "Epoch 836/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050587938816.0000 - val_loss: 4991816826880.0000\n",
            "Epoch 837/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050360922112.0000 - val_loss: 4992275578880.0000\n",
            "Epoch 838/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049969803264.0000 - val_loss: 4994938437632.0000\n",
            "Epoch 839/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050157498368.0000 - val_loss: 4990351441920.0000\n",
            "Epoch 840/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050441138176.0000 - val_loss: 4990157979648.0000\n",
            "Epoch 841/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050916143104.0000 - val_loss: 4990264934400.0000\n",
            "Epoch 842/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050631979008.0000 - val_loss: 4990697472000.0000\n",
            "Epoch 843/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050762002432.0000 - val_loss: 4992259325952.0000\n",
            "Epoch 844/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050175324160.0000 - val_loss: 4991525847040.0000\n",
            "Epoch 845/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050405486592.0000 - val_loss: 4990839029760.0000\n",
            "Epoch 846/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050441138176.0000 - val_loss: 4991650627584.0000\n",
            "Epoch 847/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050703282176.0000 - val_loss: 4993170538496.0000\n",
            "Epoch 848/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050607337472.0000 - val_loss: 4992996474880.0000\n",
            "Epoch 849/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050011222016.0000 - val_loss: 4990901944320.0000\n",
            "Epoch 850/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050125516800.0000 - val_loss: 4990382374912.0000\n",
            "Epoch 851/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050581647360.0000 - val_loss: 4992474284032.0000\n",
            "Epoch 852/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050463158272.0000 - val_loss: 4992577044480.0000\n",
            "Epoch 853/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050738409472.0000 - val_loss: 4991957860352.0000\n",
            "Epoch 854/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050395000832.0000 - val_loss: 4990677024768.0000\n",
            "Epoch 855/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050452672512.0000 - val_loss: 4990685413376.0000\n",
            "Epoch 856/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050338377728.0000 - val_loss: 4991023054848.0000\n",
            "Epoch 857/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050412826624.0000 - val_loss: 4990439522304.0000\n",
            "Epoch 858/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050326843392.0000 - val_loss: 4991108513792.0000\n",
            "Epoch 859/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050202062848.0000 - val_loss: 4994049769472.0000\n",
            "Epoch 860/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050391330816.0000 - val_loss: 4991931121664.0000\n",
            "Epoch 861/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050547568640.0000 - val_loss: 4992181207040.0000\n",
            "Epoch 862/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050474168320.0000 - val_loss: 4992922025984.0000\n",
            "Epoch 863/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050246103040.0000 - val_loss: 4991117950976.0000\n",
            "Epoch 864/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050250821632.0000 - val_loss: 4991102746624.0000\n",
            "Epoch 865/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050343620608.0000 - val_loss: 4993009057792.0000\n",
            "Epoch 866/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050405486592.0000 - val_loss: 4990969577472.0000\n",
            "Epoch 867/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050292764672.0000 - val_loss: 4993090846720.0000\n",
            "Epoch 868/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050062602240.0000 - val_loss: 4990112890880.0000\n",
            "Epoch 869/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050375077888.0000 - val_loss: 4990882545664.0000\n",
            "Epoch 870/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050352533504.0000 - val_loss: 4990763532288.0000\n",
            "Epoch 871/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049821429760.0000 - val_loss: 4994560425984.0000\n",
            "Epoch 872/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050018562048.0000 - val_loss: 4990704287744.0000\n",
            "Epoch 873/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050396049408.0000 - val_loss: 4991129485312.0000\n",
            "Epoch 874/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050155401216.0000 - val_loss: 4991430950912.0000\n",
            "Epoch 875/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049803603968.0000 - val_loss: 4993947533312.0000\n",
            "Epoch 876/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050279133184.0000 - val_loss: 4992966066176.0000\n",
            "Epoch 877/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050192625664.0000 - val_loss: 4990820679680.0000\n",
            "Epoch 878/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5049950404608.0000 - val_loss: 4992582811648.0000\n",
            "Epoch 879/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050363019264.0000 - val_loss: 4993436352512.0000\n",
            "Epoch 880/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050237190144.0000 - val_loss: 4992961871872.0000\n",
            "Epoch 881/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050074136576.0000 - val_loss: 4993560608768.0000\n",
            "Epoch 882/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050380845056.0000 - val_loss: 4991789039616.0000\n",
            "Epoch 883/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050265501696.0000 - val_loss: 4991779602432.0000\n",
            "Epoch 884/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050310590464.0000 - val_loss: 4990735220736.0000\n",
            "Epoch 885/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050251870208.0000 - val_loss: 4990757240832.0000\n",
            "Epoch 886/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050073088000.0000 - val_loss: 4990938644480.0000\n",
            "Epoch 887/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050217267200.0000 - val_loss: 4992860684288.0000\n",
            "Epoch 888/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050051067904.0000 - val_loss: 4990480941056.0000\n",
            "Epoch 889/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050124992512.0000 - val_loss: 4991866634240.0000\n",
            "Epoch 890/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049744359424.0000 - val_loss: 4995653042176.0000\n",
            "Epoch 891/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050077806592.0000 - val_loss: 4991582994432.0000\n",
            "Epoch 892/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050050543616.0000 - val_loss: 4989624778752.0000\n",
            "Epoch 893/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050509819904.0000 - val_loss: 4991174574080.0000\n",
            "Epoch 894/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049862848512.0000 - val_loss: 4989893214208.0000\n",
            "Epoch 895/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050446381056.0000 - val_loss: 4991158321152.0000\n",
            "Epoch 896/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050181615616.0000 - val_loss: 4990321557504.0000\n",
            "Epoch 897/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050431700992.0000 - val_loss: 4991337627648.0000\n",
            "Epoch 898/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050197868544.0000 - val_loss: 4993163722752.0000\n",
            "Epoch 899/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050376126464.0000 - val_loss: 4993715273728.0000\n",
            "Epoch 900/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049859702784.0000 - val_loss: 4990462590976.0000\n",
            "Epoch 901/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050409156608.0000 - val_loss: 4990139105280.0000\n",
            "Epoch 902/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049495846912.0000 - val_loss: 4993664417792.0000\n",
            "Epoch 903/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050024853504.0000 - val_loss: 4994547318784.0000\n",
            "Epoch 904/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049886441472.0000 - val_loss: 4994859270144.0000\n",
            "Epoch 905/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050067320832.0000 - val_loss: 4992388825088.0000\n",
            "Epoch 906/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049964560384.0000 - val_loss: 4990608343040.0000\n",
            "Epoch 907/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049807798272.0000 - val_loss: 4993739915264.0000\n",
            "Epoch 908/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050460012544.0000 - val_loss: 4992852295680.0000\n",
            "Epoch 909/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049875431424.0000 - val_loss: 4991358074880.0000\n",
            "Epoch 910/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049747505152.0000 - val_loss: 4993233453056.0000\n",
            "Epoch 911/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050367737856.0000 - val_loss: 4992905248768.0000\n",
            "Epoch 912/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5050085146624.0000 - val_loss: 4991614451712.0000\n",
            "Epoch 913/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049926811648.0000 - val_loss: 4993856307200.0000\n",
            "Epoch 914/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049907937280.0000 - val_loss: 4990386569216.0000\n",
            "Epoch 915/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049895878656.0000 - val_loss: 4993603600384.0000\n",
            "Epoch 916/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050266025984.0000 - val_loss: 4991296733184.0000\n",
            "Epoch 917/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050061029376.0000 - val_loss: 4991627034624.0000\n",
            "Epoch 918/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050347814912.0000 - val_loss: 4990707433472.0000\n",
            "Epoch 919/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050320551936.0000 - val_loss: 4991656394752.0000\n",
            "Epoch 920/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049767428096.0000 - val_loss: 4989943545856.0000\n",
            "Epoch 921/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050144391168.0000 - val_loss: 4990677024768.0000\n",
            "Epoch 922/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049803603968.0000 - val_loss: 4992458555392.0000\n",
            "Epoch 923/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050232995840.0000 - val_loss: 4991966248960.0000\n",
            "Epoch 924/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049940443136.0000 - val_loss: 4992452788224.0000\n",
            "Epoch 925/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049900597248.0000 - val_loss: 4990371364864.0000\n",
            "Epoch 926/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049912131584.0000 - val_loss: 4991832031232.0000\n",
            "Epoch 927/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050137575424.0000 - val_loss: 4990770348032.0000\n",
            "Epoch 928/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049883820032.0000 - val_loss: 4990108172288.0000\n",
            "Epoch 929/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050000736256.0000 - val_loss: 4990673354752.0000\n",
            "Epoch 930/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050249248768.0000 - val_loss: 4991056609280.0000\n",
            "Epoch 931/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049918947328.0000 - val_loss: 4992442826752.0000\n",
            "Epoch 932/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049806749696.0000 - val_loss: 4990794465280.0000\n",
            "Epoch 933/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049198575616.0000 - val_loss: 4988864561152.0000\n",
            "Epoch 934/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049922093056.0000 - val_loss: 4992096272384.0000\n",
            "Epoch 935/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049927860224.0000 - val_loss: 4991113756672.0000\n",
            "Epoch 936/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049803603968.0000 - val_loss: 4993068826624.0000\n",
            "Epoch 937/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049223741440.0000 - val_loss: 4989654138880.0000\n",
            "Epoch 938/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050498285568.0000 - val_loss: 4990806523904.0000\n",
            "Epoch 939/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049714999296.0000 - val_loss: 4993663369216.0000\n",
            "Epoch 940/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049694552064.0000 - val_loss: 4991043502080.0000\n",
            "Epoch 941/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050165362688.0000 - val_loss: 4992962920448.0000\n",
            "Epoch 942/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049896927232.0000 - val_loss: 4992748486656.0000\n",
            "Epoch 943/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049938870272.0000 - val_loss: 4994639069184.0000\n",
            "Epoch 944/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049901645824.0000 - val_loss: 4995671916544.0000\n",
            "Epoch 945/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049923141632.0000 - val_loss: 4990722637824.0000\n",
            "Epoch 946/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049500565504.0000 - val_loss: 4992640483328.0000\n",
            "Epoch 947/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5049739640832.0000 - val_loss: 4992875364352.0000\n",
            "Epoch 948/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050040582144.0000 - val_loss: 4992042270720.0000\n",
            "Epoch 949/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050052640768.0000 - val_loss: 4992595394560.0000\n",
            "Epoch 950/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049956696064.0000 - val_loss: 4992954007552.0000\n",
            "Epoch 951/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050375077888.0000 - val_loss: 4991936888832.0000\n",
            "Epoch 952/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050065223680.0000 - val_loss: 4990979014656.0000\n",
            "Epoch 953/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049813565440.0000 - val_loss: 4990562729984.0000\n",
            "Epoch 954/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049816186880.0000 - val_loss: 4990672306176.0000\n",
            "Epoch 955/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049838206976.0000 - val_loss: 4990870487040.0000\n",
            "Epoch 956/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049626918912.0000 - val_loss: 4989898457088.0000\n",
            "Epoch 957/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049567150080.0000 - val_loss: 4993446838272.0000\n",
            "Epoch 958/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5049752748032.0000 - val_loss: 4994644312064.0000\n",
            "Epoch 959/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050310590464.0000 - val_loss: 4992618463232.0000\n",
            "Epoch 960/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049881722880.0000 - val_loss: 4991530565632.0000\n",
            "Epoch 961/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049856032768.0000 - val_loss: 4990183145472.0000\n",
            "Epoch 962/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049938870272.0000 - val_loss: 4990057316352.0000\n",
            "Epoch 963/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049942016000.0000 - val_loss: 4992988610560.0000\n",
            "Epoch 964/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050065747968.0000 - val_loss: 4990691180544.0000\n",
            "Epoch 965/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049774768128.0000 - val_loss: 4990323130368.0000\n",
            "Epoch 966/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5049995493376.0000 - val_loss: 4991488098304.0000\n",
            "Epoch 967/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049508954112.0000 - val_loss: 4989759520768.0000\n",
            "Epoch 968/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050109788160.0000 - val_loss: 4989822959616.0000\n",
            "Epoch 969/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5049998639104.0000 - val_loss: 4992691863552.0000\n",
            "Epoch 970/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049650511872.0000 - val_loss: 4990663917568.0000\n",
            "Epoch 971/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5050068893696.0000 - val_loss: 4991017811968.0000\n",
            "Epoch 972/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050030096384.0000 - val_loss: 4991290966016.0000\n",
            "Epoch 973/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050274414592.0000 - val_loss: 4991652200448.0000\n",
            "Epoch 974/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049589694464.0000 - val_loss: 4992225771520.0000\n",
            "Epoch 975/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049849217024.0000 - val_loss: 4990226137088.0000\n",
            "Epoch 976/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5050141769728.0000 - val_loss: 4990991073280.0000\n",
            "Epoch 977/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5050461061120.0000 - val_loss: 4993515520000.0000\n",
            "Epoch 978/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049404620800.0000 - val_loss: 4990755143680.0000\n",
            "Epoch 979/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049869139968.0000 - val_loss: 4989334323200.0000\n",
            "Epoch 980/1000\n",
            "861/861 [==============================] - 5s 6ms/step - loss: 5050092486656.0000 - val_loss: 4991851429888.0000\n",
            "Epoch 981/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049705562112.0000 - val_loss: 4989616914432.0000\n",
            "Epoch 982/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049983959040.0000 - val_loss: 4990184194048.0000\n",
            "Epoch 983/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049719193600.0000 - val_loss: 4989462249472.0000\n",
            "Epoch 984/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5049727057920.0000 - val_loss: 4991573032960.0000\n",
            "Epoch 985/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049331220480.0000 - val_loss: 4992874315776.0000\n",
            "Epoch 986/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049731776512.0000 - val_loss: 4992562888704.0000\n",
            "Epoch 987/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049816186880.0000 - val_loss: 4991067095040.0000\n",
            "Epoch 988/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049838206976.0000 - val_loss: 4992413466624.0000\n",
            "Epoch 989/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049778438144.0000 - val_loss: 4989854416896.0000\n",
            "Epoch 990/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049948307456.0000 - val_loss: 4991616024576.0000\n",
            "Epoch 991/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049853935616.0000 - val_loss: 4991393202176.0000\n",
            "Epoch 992/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049654181888.0000 - val_loss: 4990518689792.0000\n",
            "Epoch 993/1000\n",
            "861/861 [==============================] - 3s 4ms/step - loss: 5049702416384.0000 - val_loss: 4992084213760.0000\n",
            "Epoch 994/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049570820096.0000 - val_loss: 4989471162368.0000\n",
            "Epoch 995/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049751699456.0000 - val_loss: 4990111318016.0000\n",
            "Epoch 996/1000\n",
            "861/861 [==============================] - 4s 5ms/step - loss: 5049722339328.0000 - val_loss: 4990501388288.0000\n",
            "Epoch 997/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049652609024.0000 - val_loss: 4992388300800.0000\n",
            "Epoch 998/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049829294080.0000 - val_loss: 4991416270848.0000\n",
            "Epoch 999/1000\n",
            "861/861 [==============================] - 5s 5ms/step - loss: 5049868615680.0000 - val_loss: 4992458555392.0000\n",
            "Epoch 1000/1000\n",
            "861/861 [==============================] - 4s 4ms/step - loss: 5049691930624.0000 - val_loss: 4993785528320.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation loss values\n",
        "plt.plot(model.history['loss'])\n",
        "plt.plot(model.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "AcwnsOcJIwRQ",
        "outputId": "32e0c9d9-e353-4357-9a0b-f4ec968faa53"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "rmse = math.sqrt(4993785528320.0000)\n",
        "print(f\"root mean squred mean: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9iGTGXTWdDD",
        "outputId": "23c5dcfa-f31b-46a5-8bc1-3eae086baca8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root mean squred mean: 2234677.9473382737\n"
          ]
        }
      ]
    }
  ]
}